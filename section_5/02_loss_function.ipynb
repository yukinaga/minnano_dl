{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "02_loss_function.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMozMecIxkltg2QnAPG+AXv",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yukinaga/minnano_dl/blob/main/section_5/02_loss_function.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t1HGlYzi4u7a"
      },
      "source": [
        "# 「誤差」の定義\n",
        "出力と正解の間で「誤差」を定義します。  \n",
        "誤差には様々な定義の仕方がありますが、今回は「二乗和誤差」について解説します。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fOqhfIac2eK3"
      },
      "source": [
        "## 二乗和誤差\n",
        "\n",
        "ニューラルネットワークには複数の出力と、それぞれに対応した正解があります。  \n",
        "これらを使い、二乗和誤差は以下の式で定義されます。  \n",
        "\n",
        "$$ E = \\frac{1}{2} \\sum_{k=1}^n(y_k-t_k)^2 $$\n",
        "\n",
        "$y_k$は出力、$t_k$は正解、$n$は出力層のニューロン数を表します。  \n",
        "$\\frac{1}{2}$をかけるのは、微分した形を扱いやすくするためです。  \n",
        "\n",
        "ここで、総和を取る前の個々の二乗誤差をグラフに描画します。 \n",
        "\n",
        "$$E_k = \\frac{1}{2}(y_k-t_k)^2$$\n",
        "\n",
        "以下のコードにより、`y`の値が0.25、0.5、0.75のとき、`t`の値とともに二乗誤差がどう変化するのかを確認します。  \n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aEQhZssn94cy"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def square_error(y, t):\n",
        "    return (y - t)**2/2  # 二乗誤差\n",
        "\n",
        "y = np.linspace(0, 1)\n",
        "ts = [0.25, 0.5, 0.75]\n",
        "for t in ts:\n",
        "    plt.plot(y, square_error(y, t), label=\"t=\"+str(t))\n",
        "    \n",
        "plt.legend()\n",
        "plt.xlabel(\"y\")\n",
        "plt.ylabel(\"Error\")\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZSujlDCbOUJ8"
      },
      "source": [
        "入力と正解が等しいときに最小値の0をとり、入力と正解が離れるについて誤差は次第に大きくなっていきます。  \n",
        "これを全ての出力と正解のペアで総和をとることにより、ある入力に対する誤差の大きさが決まることになります。  "
      ]
    }
  ]
}