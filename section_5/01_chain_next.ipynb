{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "01_chain_next.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyP6YZnCuM4KofkGX+znO3s+",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yukinaga/minnano_dl/blob/main/section_5/01_chain_next.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cFCD4jy31h08"
      },
      "source": [
        "# 連鎖律の拡張\n",
        "ニューラルネットワークの学習で使用できるように、連鎖律をより汎用的な形に拡張します。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tr2OdPkdN_7O"
      },
      "source": [
        "## 複雑な合成関数\n",
        "\n",
        "Section2では以下のシンプルな合成関数を扱いました。  \n",
        "\n",
        "$$ \\begin{aligned} \\\\\n",
        "y & = f(u) \\\\\n",
        "u & = g(x) \\\\\n",
        "\\end{aligned} $$\n",
        "\n",
        "この場合、$y$は$u$の関数で、$u$は$x$の関数です。  \n",
        "\n",
        "これを、以下のように多変数関数に拡張します。\n",
        "\n",
        "（式1）  \n",
        "$$ y = f(u_1,u_2,\\cdots, u_i, \\cdots, u_n)$$\n",
        "$$u_i = g_i(x_1, x_2, \\cdots, x_j, \\cdots, x_m)$$\n",
        "\n",
        "ここで、$1\\leq i \\leq n$、$1\\leq j \\leq m$です。  \n",
        "$y$は$u_1,u_2,\\cdots, u_i, \\cdots, u_n$の関数で、$u_i$は$x_1, x_2, \\cdots, x_j, \\cdots, x_m$の関数です。  \n",
        "$g_i$は添字ごとに異なる関数です。  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8XjVWCfO2RUM"
      },
      "source": [
        "## 連鎖律の拡張\n",
        "\n",
        "（式1）の合成関数$y$を$x_j$で偏微分する場合には、以下の通り総和の形で連鎖律を適用できます。    \n",
        "\n",
        "（式2） \n",
        "$$ \\frac{\\partial y}{\\partial x_j} = \\sum_{i=1}^{n}\\frac{\\partial y}{\\partial u_i}\\frac{\\partial u_i}{\\partial x_j}$$ \n",
        "\n",
        "この式が実際に機能することを確かめましょう。  \n",
        "例として、以下の関数を扱います。  \n",
        "（式3）\n",
        "$$ \\begin{aligned} \\\\\n",
        "y &= (x_1^2+x_2+1)(x_2-1)+x_2-1 \\\\\n",
        "\\end{aligned} $$\n",
        "\n",
        "この関数は以下のように展開できます。  \n",
        "（式4）  \n",
        "$$ \\begin{aligned} \\\\\n",
        "y &= x_1^2x_2 - x_1^2 + x_2^2 - x_2 + x_2 -1 + x_2 -1 \\\\\n",
        "&= x_1^2x_2 - x_1^2 + x_2^2 + x_2 - 2\n",
        "\\end{aligned} $$\n",
        "\n",
        "この（式4）は以下のように偏微分することができます。\n",
        "\n",
        "（式5）\n",
        "$$ \\frac{\\partial y}{\\partial x_1} = 2x_1x_2 - 2x_1 $$\n",
        "$$ \\frac{\\partial y}{\\partial x_2} = x_1^2 + 2x_2 + 1 $$\n",
        "\n",
        "ここで、（式2）の連鎖律を使っても同じ結果が得られることを確認します。  \n",
        "以下の通りに$u_1$と$u_2$を設定します。  \n",
        "\n",
        "$$u_1=x_1^2+x_2+1$$\n",
        "$$u_2=x_2-1$$\n",
        "\n",
        "このとき、（式3）は次のように表されます。  \n",
        "\n",
        "$$y=u_1u_2+u_2$$\n",
        "\n",
        "ここで、（式2）を使います。\n",
        "\n",
        "$$ \\begin{aligned} \\\\\n",
        "\\frac{\\partial y}{\\partial x_1} &= \\frac{\\partial y}{\\partial u_1} \\frac{\\partial u_1}{\\partial x_1} + \\frac{\\partial y}{\\partial u_2} \\frac{\\partial u_2}{\\partial x_1} \\\\\n",
        "& = 2u_2 x_1 \\\\\n",
        "& = 2x_1x_2 - 2x_1\n",
        "\\end{aligned} $$\n",
        "\n",
        "$$ \\begin{aligned} \\\\\n",
        "\\frac{\\partial y}{\\partial x_2} &= \\frac{\\partial y}{\\partial u_1} \\frac{\\partial u_1}{\\partial x_2} + \\frac{\\partial y}{\\partial u_2} \\frac{\\partial u_2}{\\partial x_2} \\\\\n",
        "& = u_2 + (u_1+1) \\\\\n",
        "& = x_1^2 +2x_2 + 1\n",
        "\\end{aligned} $$\n",
        "\n",
        "連鎖律が機能し、（式5）と同じ結果が得られました。  \n",
        "ニューラルネットワークが学習するためのアルゴリズム「バックプロパゲーション」では、このような連鎖律が必要不可欠です。  "
      ]
    }
  ]
}